import io
import base64
import requests
import numpy as np
from typing import Optional, Any
import os
import time
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError
import math
from PIL import Image, ImageDraw
from android_world.env import representation_utils
# å¯¼å…¥é¡¹ç›®ä¸­å·²æœ‰çš„å‡½æ•°
from android_world.agents.infer import array_to_jpeg_bytes, image_to_jpeg_bytes

# å®šä¹‰å¸¸é‡
ERROR_CALLING_LLM = "ERROR_CALLING_LLM"

# ç³»ç»ŸæŒ‡ä»¤
SYSTEM_PROMPT = """You are an expert **UI State Transition Simulator** and **Frontend Developer**.
Your task is to predict the **NEXT UI STATE** based on a screenshot of the current state and a user interaction.

### 1. IMAGE INTERPRETATION RULES
The input image contains visual cues denoting the user's action. You must interpret them as follows:
*   **Red Circle**: Indicates a **Click** or **Long Press** target at that location.
*   **Red Arrow**: Indicates a **Scroll** or **Swipe**.
    *   The arrow points in the direction of finger movement.
    *   *Example*: An arrow pointing UP means the finger slides up, pushing content up (Scrolling Down).
*   **Note**: These cues exist ONLY to show the action. **DO NOT render these red circles or arrows in your output HTML.**

### 2. CRITICAL STRUCTURAL RULES (MUST FOLLOW)
*   **Format**: Output ONLY raw HTML. Start with `<!DOCTYPE html>` and end with `</html>`.
*   **Root Element**: All visible content MUST be wrapped in:
    `<div id="render-target"> ... </div>`
*   **Container Style**: `#render-target` must have:
    `width: 1080px; height: 2400px; position: relative; overflow: hidden;`
    (Apply background colors and shadows here, NOT on the body).
*   **Body Style**: The `<body>` tag must have `margin: 0; padding: 0; background: transparent;`.
*   **Layout**: Do NOT center the body. Let `#render-target` sit at (0,0).

### 3. CONTENT GENERATION LOGIC
*   **Transition**: Analyze the action. If the user clicks a button, show the *result* (e.g., a menu opens, a checkbox checks, page navigates).
*   **Images**: Use semantic text placeholders. DO NOT use real URLs.
    *   Format: `<div style="...">[IMG: description]</div>`
*   **Icons**: Use simple inline SVG paths or Unicode.

### 4. OUTPUT REQUIREMENT
*   Do NOT generate Markdown blocks (```html).
*   Do NOT provide explanations or conversational text.
*   Output the code directly.
"""

# ç”¨æˆ·æŒ‡ä»¤ï¼Œå¡«å……action
USER_PROMPT_TEMPLATE = """
### INPUT CONTEXT
1.  **User Intent**: "Interact with UI."
2.  **Interaction Details**:
    *   **Description**: {semantic_desc}

### COMMAND
Based on the image and the interaction data above, generate the **HTML for the RESULTING UI STATE** (what the screen looks like *after* this action).
"""



# å®šä¹‰gpt5è¯·æ±‚çš„ç±»ï¼Œå‚è€ƒinfer.pyçš„å®ç°
class MLLMInferencer:
    def __init__(self, model_name="gpt-5", temperature=0.0, max_retry=3):
        self.openai_api_key = os.environ.get('OPENAI_API_KEY')
        if not self.openai_api_key:
            raise RuntimeError('OpenAI API key not set.')
        self.model = model_name
        self.temperature = temperature
        self.max_retry = max_retry
        self.RETRY_WAITING_SECONDS = 20  
    
    def encode_image(self, image: np.ndarray) -> str:
        """Encode image to base64 string using project's existing function."""
        return base64.b64encode(array_to_jpeg_bytes(image)).decode('utf-8')
    
    # è¾“å…¥ç”¨æˆ·çš„promptï¼ˆåŒ…å«actionï¼‰ï¼Œå½“å‰guiå›¾åƒï¼Œè¿”å›MLLMçš„è¾“å‡ºï¼ˆé¢„æœŸæ˜¯çº¯htmlä»£ç ï¼‰
    def predict_mm(self, user_prompt: str, images: list[np.ndarray]) -> tuple[str, Optional[bool], Any]:
        """Send prompt and images to GPT-5 and get response, following the same format as infer.py."""
        headers = {
            'Content-Type': 'application/json',
            # 'Authorization': f'Bearer {self.openai_api_key}',  
            'Authorization': f'Bearer sk-LFjq1ToJQrknIHrrohUMA21z7iSsETOyhfUUuko6hJsRozXU', 
        }

        payload = {
            'model': self.model,
            'temperature': self.temperature,
            'messages': [
                {
                    'role': 'system',
                    'content': [
                        {'type': 'text', 'text': SYSTEM_PROMPT},  # ç³»ç»Ÿæç¤ºï¼Œå®šä¹‰è§’è‰²å’Œä»»åŠ¡
                    ],
                },
                {
                    'role': 'user',
                    'content': [
                        {'type': 'text', 'text': user_prompt},
                    ],
                }
            ],
        }

        # print("å¼€å§‹ç¼–ç å›¾åƒ")
        for image in images:
            payload['messages'][1]['content'].append({
                'type': 'image_url',
                'image_url': {
                    'url': f'data:image/jpeg;base64,{self.encode_image(image)}'
                },
            })
        # print("å›¾åƒç¼–ç å®Œæ¯•")

        counter = self.max_retry
        wait_seconds = self.RETRY_WAITING_SECONDS
        while counter > 0:
            try:
                # print(f"å¼€å§‹è¯·æ±‚{self.model}")
                response = requests.post(
                    # 'https://tao.plus7.plus/v1/chat/completions',  # ä½¿ç”¨ä¸é¡¹ç›®ä¸­ç›¸åŒçš„APIç«¯ç‚¹
                    'https://chat.intern-ai.org.cn/api/v1/chat/completions',  # ä½¿ç”¨ä¸é¡¹ç›®ä¸­ç›¸åŒçš„APIç«¯ç‚¹
                    headers=headers,
                    json=payload,
                )
                if response.ok and 'choices' in response.json():
                    # print("è¯·æ±‚æˆåŠŸ")
                    return (
                        response.json()['choices'][0]['message']['content'],
                        None,
                        response,
                    )
                print(
                    'Error calling OpenAI API with error message: '
                    + response.json()['error']['message']
                )
                time.sleep(wait_seconds)
                wait_seconds *= 2
            except Exception as e:  # pylint: disable=broad-exception-caught
                # Catch all exceptions during LLM calls
                print("è¯·æ±‚å¤±è´¥")
                time.sleep(wait_seconds)
                wait_seconds *= 2
                counter -= 1
        return ERROR_CALLING_LLM, None, None


def render_aligned_png(html_path, output_path):
    """
    æ™ºèƒ½æ¸²æŸ“ HTML ä¸º PNGã€‚
    ç­–ç•¥ï¼š
    1. ä¼˜å…ˆå°è¯•å…¨èµ„æºåŠ è½½ (High Fidelity)ã€‚
    2. å¦‚æœè¶…æ—¶ï¼Œè‡ªåŠ¨é™çº§ä¸ºæ‹¦æˆªå­—ä½“æ¨¡å¼ (High Reliability)ã€‚
    """
    
    # --- 1. å°ºå¯¸è·å– ---
    target_width, target_height = 1080, 2400 

    abs_html_path = os.path.abspath(html_path)

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        
        # ä¸Šä¸‹æ–‡é…ç½® (ä¸€æ¬¡æ€§é…ç½®å¥½è§†å£)
        context = browser.new_context(
            viewport={'width': target_width, 'height': target_height},
            device_scale_factor=1.0
        )

        # ============================================================
        # ğŸŸ¢ å°è¯• 1: é«˜ä¿çœŸæ¨¡å¼ (ä¸æ‹¦æˆªï¼Œç­‰å¾…å­—ä½“åŠ è½½)
        # ============================================================
        page = context.new_page()
        success = False
        
        try:
            # print(f"   ğŸ”„ å°è¯•é«˜ä¿çœŸæ¸²æŸ“...")
            
            # è¿™é‡Œçš„ timeout è®¾ä¸º 30000ms (30ç§’)ã€‚
            # å¦‚æœ 6ç§’å†…å­—ä½“ä¸‹ä¸ä¸‹æ¥ï¼Œè¯´æ˜ç½‘ç»œå¤§æ¦‚ç‡ä¸è¡Œï¼Œä¸å¦‚èµ¶ç´§åˆ‡ Plan B
            page.goto(f"file://{abs_html_path}", wait_until="load", timeout=30000)
            
            # ç­‰å¾…ç½‘ç»œç©ºé—² (ç¡®ä¿å›¾ç‰‡å’Œå­—ä½“éƒ½å¥½äº†)
            # ç¨å¾®ç»™ä¸€ç‚¹ç¼“å†²
            page.wait_for_load_state("networkidle", timeout=2000)
            
            page.screenshot(path=output_path, omit_background=True)
            print(f"âœ” [High-Fi] å·²ç”Ÿæˆ: {output_path}")
            success = True

        except PlaywrightTimeoutError:
            print(f"   âš ï¸ é«˜ä¿çœŸåŠ è½½è¶…æ—¶ (å­—ä½“/å›¾ç‰‡å¤ªæ…¢)ï¼Œåˆ‡æ¢åˆ°æé€Ÿæ¨¡å¼...")
        except Exception as e:
            print(f"   âš ï¸ é«˜ä¿çœŸæ¸²æŸ“å‡ºé”™: {e}ï¼Œåˆ‡æ¢åˆ°æé€Ÿæ¨¡å¼...")
        finally:
            # æ— è®ºæˆåŠŸå¤±è´¥ï¼Œå…ˆå…³æ‰è¿™ä¸ªé¡µé¢ï¼Œæ¸…ç†èµ„æº
            page.close()

        # ============================================================
        # ğŸ”´ å°è¯• 2: æé€Ÿå…œåº•æ¨¡å¼ (å¦‚æœå°è¯• 1 å¤±è´¥)
        # ============================================================
        if not success:
            page_fallback = context.new_page()
            try:
                # 1. æ‹¦æˆªå­—ä½“å’Œ Google è¯·æ±‚
                page_fallback.route("**/*.{woff,woff2,ttf,otf,eot}", lambda route: route.abort())
                page_fallback.route("**/*fonts.googleapis.com*", lambda route: route.abort())
                page_fallback.route("**/*fonts.gstatic.com*", lambda route: route.abort())
                
                # 2. æ³¨å…¥ç³»ç»Ÿå­—ä½“ CSS
                page_fallback.add_init_script("""
                    const style = document.createElement('style');
                    style.innerHTML = `
                        * { font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif !important; }
                    `;
                    document.head.appendChild(style);
                """)

                # 3. å¿«é€ŸåŠ è½½ (åªç­‰ DOM)
                page_fallback.goto(f"file://{abs_html_path}", wait_until="domcontentloaded", timeout=15000)
                
                # ç®€å•ç¼“å†²
                page_fallback.wait_for_timeout(500)
                
                page_fallback.screenshot(path=output_path, omit_background=True)
                print(f"âœ” [Fallback] å·²ç”Ÿæˆ: {output_path}")
                
            except Exception as e:
                print(f"âŒ å½»åº•å¤±è´¥ [{os.path.basename(html_path)}]: {e}")
            finally:
                page_fallback.close()

        browser.close()

        return success


# PNGå›¾åƒä¸image_arrayçš„ç›¸äº’è½¬æ¢å‡½æ•°
def png_to_image_array(png_path: str) -> np.ndarray:
    """å°†PNGæ–‡ä»¶è½¬æ¢ä¸ºNumPyæ•°ç»„æ ¼å¼çš„image_array
    
    Args:
        png_path: PNGå›¾åƒæ–‡ä»¶çš„è·¯å¾„
        
    Returns:
        NumPyæ•°ç»„æ ¼å¼çš„å›¾åƒæ•°æ®
    """
    with Image.open(png_path) as img:
        # ç¡®ä¿å›¾åƒæ˜¯RGBæ¨¡å¼
        if img.mode != 'RGB':
            img = img.convert('RGB')
        return np.array(img)

def image_array_to_png(image_array: np.ndarray, output_path: Optional[str] = None) -> bytes:
    """å°†NumPyæ•°ç»„æ ¼å¼çš„image_arrayè½¬æ¢ä¸ºPNGæ ¼å¼
    
    Args:
        image_array: NumPyæ•°ç»„æ ¼å¼çš„å›¾åƒæ•°æ®
        output_path: å¯é€‰çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæä¾›åˆ™ä¿å­˜åˆ°æ–‡ä»¶
        
    Returns:
        PNGæ ¼å¼çš„å›¾åƒå­—èŠ‚æ•°æ®
    """
    # åˆ›å»ºPILå›¾åƒå¯¹è±¡
    img = Image.fromarray(image_array)
    
    # åˆ›å»ºå­—èŠ‚æµ
    png_bytes = io.BytesIO()
    
    # ä¿å­˜ä¸ºPNGæ ¼å¼
    img.save(png_bytes, format='PNG')
    png_bytes = png_bytes.getvalue()
    
    # å¦‚æœæä¾›äº†è¾“å‡ºè·¯å¾„ï¼Œåˆ™ä¿å­˜åˆ°æ–‡ä»¶
    if output_path:
        with open(output_path, 'wb') as f:
            f.write(png_bytes)
    
    return png_bytes


def android_world_to_control(android_world: dict, ui_elements: list[representation_utils.UIElement]) -> dict:
    """Convert android_world format to android_control format."""
    
    action_type = android_world.get("action_type")
    
    # ACçš„jsonæ ¼å¼åˆå§‹åŒ–
    control_action = {"name": "mobile_use", "arguments": {}}
    
    # å¦‚æœæ˜¯"status"çŠ¶æ€ç±»å‹ï¼Œè½¬æˆACçš„"action": "terminate"
    if action_type == "status":
        goal_status = android_world.get("goal_status")
        if goal_status == "complete":
            control_action["arguments"]["action"] = "terminate"
            control_action["arguments"]["status"] = "success"
        elif goal_status == "infeasible":
            control_action["arguments"]["action"] = "terminate"
            control_action["arguments"]["status"] = "failure"
    
    # ACä¸æ”¯æŒanswer
    elif action_type == "answer":
        text = android_world.get("text")
        control_action["arguments"]["action"] = "answer"
        control_action["arguments"]["text"] = text
    
    # å¯¹äºç‚¹å‡»äº‹ä»¶
    elif action_type == "click":
        index = android_world.get("index")  # è·å–ç‚¹å‡»äº‹ä»¶æ“ä½œçš„element
        if index is not None and index != '':
            index = int(index)
        # æ ¹æ®indexä»ui_elementsä¸­æ£€ç´¢å¯¹åº”çš„å…ƒç´ 
        print(index, len(ui_elements))
        if index is not None and 0 <= index < len(ui_elements):
            ui_element = ui_elements[index]
            if ui_element.bbox_pixels:
                center_x, center_y = ui_element.bbox_pixels.center
                control_action["arguments"]["action"] = "click"
                control_action["arguments"]["coordinate"] = [int(center_x), int(center_y)]
            else:
                print(f"indexä¸º{index},åˆ—è¡¨æ€»é•¿ä¸º{len(ui_elements)}, indexä¸åˆæ³•ï¼ï¼ï¼")
    
    elif action_type == "long_press":
        index = android_world.get("index")
        if index is not None and index != '':
            index = int(index)
        if index is not None and 0 <= index < len(ui_elements):
            ui_element = ui_elements[index]
            if ui_element.bbox_pixels:
                center_x, center_y = ui_element.bbox_pixels.center
                control_action["arguments"]["action"] = "long_press"
                control_action["arguments"]["coordinate"] = [int(center_x), int(center_y)]
                # Default time if not provided
                control_action["arguments"]["time"] = 1.0
    
    elif action_type == "input_text":
        text = android_world.get("text")
        index = android_world.get("index")
        if text is not None:
            control_action["arguments"]["action"] = "type"
            control_action["arguments"]["text"] = text
            # Note: input_text in android_world includes clicking the field, but in android_control
            # we need separate click and type actions. However, the requirement says to convert to
            # android_control format, so we'll just do the type part here.
    
    elif action_type == "keyboard_enter":
        control_action["arguments"]["action"] = "key"
        control_action["arguments"]["key_code"] = "enter"
    
    elif action_type == "navigate_home":
        control_action["arguments"]["action"] = "system_button"
        control_action["arguments"]["button"] = "home"
    
    elif action_type == "navigate_back":
        control_action["arguments"]["action"] = "system_button"
        control_action["arguments"]["button"] = "back"
    
    elif action_type == "scroll":
        direction = android_world.get("direction")
        index = android_world.get("index")
        if index is not None and index != '':
            index = int(index)
        
        control_action["arguments"]["action"] = "swipe"
        
        # For scroll, we need to determine the swipe coordinates
        # If index is provided, use that element's center; otherwise, use screen center
        if index is not None and index != '' and 0 <= index < len(ui_elements):
            ui_element = ui_elements[index]
            if ui_element.bbox_pixels:
                center_x, center_y = ui_element.bbox_pixels.center
        else:
            # Default to screen center (assuming typical phone resolution)
            center_x, center_y = 540, 1200
        
        # Determine swipe coordinates based on direction
        if direction == "up":
            control_action["arguments"]["coordinate"] = [int(center_x), int(center_y + 200)]
            control_action["arguments"]["coordinate2"] = [int(center_x), int(center_y - 200)]
        elif direction == "down":
            control_action["arguments"]["coordinate"] = [int(center_x), int(center_y - 200)]
            control_action["arguments"]["coordinate2"] = [int(center_x), int(center_y + 200)]
        elif direction == "left":
            control_action["arguments"]["coordinate"] = [int(center_x + 200), int(center_y)]
            control_action["arguments"]["coordinate2"] = [int(center_x - 200), int(center_y)]
        elif direction == "right":
            control_action["arguments"]["coordinate"] = [int(center_x - 200), int(center_y)]
            control_action["arguments"]["coordinate2"] = [int(center_x + 200), int(center_y)]
    
    elif action_type == "open_app":
        app_name = android_world.get("app_name")
        if app_name is not None:
            control_action["arguments"]["action"] = "open"
            control_action["arguments"]["text"] = app_name
    
    elif action_type == "wait":
        control_action["arguments"]["action"] = "wait"
        control_action["arguments"]["time"] = 1.0  # Default wait time
    
    return control_action


class SimpleVisualizer:
    def __init__(self):
        # é¢„å®šä¹‰é¢œè‰²
        self.fill_color = (255, 0, 0, 100)    # åŠé€æ˜çº¢ (å¡«å……)
        self.outline_color = (255, 0, 0, 255) # å®å¿ƒçº¢ (è¾¹æ¡†)
        self.arrow_width = 15                 # ç®­å¤´çº¿å®½
        self.click_radius = 40                # ç‚¹å‡»åœ†åœˆåŠå¾„

    def visualize(self, image, action):
        """
        æ ¸å¿ƒæ–¹æ³•ï¼šç»˜åˆ¶æ“ä½œå¹¶ä¿å­˜ã€‚
        
        :param src_path:    è¾“å…¥å›¾ç‰‡è·¯å¾„
        :param save_path:   è¾“å‡ºå›¾ç‰‡è·¯å¾„
        :param action_type: 'click' æˆ– 'swipe' (ä¹Ÿå¯ä»¥å« 'scroll')
        :param points:      åæ ‡æ•°æ®
                            - click: [x, y]
                            - swipe: [[start_x, start_y], [end_x, end_y]]
        """
        # print("visualizeä¸­ä¼ å…¥çš„actionä¸ºï¼š", action)
        # è½¬æ¢ä¸º RGBA ä»¥æ”¯æŒåŠé€æ˜ç»˜åˆ¶
        image = image.convert("RGBA")
        # åˆ›å»ºä¸€ä¸ªé€æ˜å›¾å±‚ç”¨äºç»˜åˆ¶
        overlay = Image.new('RGBA', image.size, (255, 255, 255, 0))
        draw = ImageDraw.Draw(overlay)

        action_type = action['action']

        # --- ç»˜åˆ¶é€»è¾‘ ---
        if action_type in ["click", "tap", "long_press"]:
            print(f"âœ… åŠ¨ä½œç±»å‹ä¸º: {action_type}")
            self._draw_click(draw, action['coordinate'])
        elif action_type in ["scroll"]:
            print(f"âœ… åŠ¨ä½œç±»å‹ä¸º: {action_type}")
            self._draw_swipe(draw, [action['coordinate'], action['coordinate2']])
        else:
            print(f"âš ï¸ æœªçŸ¥åŠ¨ä½œç±»å‹: {action_type}")
            return image

        # åˆå¹¶å›¾å±‚å¹¶è½¬æ¢ä¸º RGB (å»é™¤ Alpha é€šé“ä»¥ä¾¿ä¿å­˜ä¸º jpg/png)
        final_img = Image.alpha_composite(image, overlay).convert("RGB")

        return final_img

    def _draw_click(self, draw, point):
        """ç”»åœ†åœˆ"""
        if not point or len(point) < 2: return
        cx, cy = point[0], point[1]
        r = self.click_radius
        # ç»˜åˆ¶ï¼š(å·¦ä¸Šè§’x, å·¦ä¸Šè§’y, å³ä¸‹è§’x, å³ä¸‹è§’y)
        draw.ellipse((cx - r, cy - r, cx + r, cy + r), 
                     fill=self.fill_color, outline=self.outline_color, width=5)

    def _draw_swipe(self, draw, points):
        """ç”»ç®­å¤´"""
        # points åº”è¯¥æ˜¯ [[x1, y1], [x2, y2]]
        if not points or len(points) < 2: return
        
        start = tuple(points[0]) # èµ·ç‚¹
        end = tuple(points[1])   # ç»ˆç‚¹
        
        # 1. ç”»çº¿
        draw.line([start, end], fill=self.outline_color, width=self.arrow_width)
        
        # 2. ç”»ç®­å¤´å¤´éƒ¨ (æ•°å­¦è®¡ç®—)
        x1, y1 = start
        x2, y2 = end
        arrow_len = 50
        angle = math.atan2(y2 - y1, x2 - x1)
        
        # ç®­å¤´ä¸¤ç¿¼åæ ‡
        p1_x = x2 - arrow_len * math.cos(angle - math.pi / 6)
        p1_y = y2 - arrow_len * math.sin(angle - math.pi / 6)
        p2_x = x2 - arrow_len * math.cos(angle + math.pi / 6)
        p2_y = y2 - arrow_len * math.sin(angle + math.pi / 6)
        
        # ç»˜åˆ¶ä¸‰è§’å½¢ç®­å¤´å¤´
        draw.polygon([(x2, y2), (p1_x, p1_y), (p2_x, p2_y)], fill=self.outline_color)

viz = SimpleVisualizer()


# ä¿®æ”¹åçš„post_figure_actionå‡½æ•°
def _post_figure_action(inferencer, image_array, action, html_save_path, idx):

    # 1. åˆ›å»ºinferencerå®ä¾‹ï¼ˆAPIå¯†é’¥ä»ç¯å¢ƒå˜é‡è·å–ï¼‰    
    user_prompt = USER_PROMPT_TEMPLATE.format(
        semantic_desc=action,
    )

    # 2. è°ƒç”¨gpt5 APIè·å–HTMLå“åº”
    response_text, _, _ = inferencer.predict_mm(user_prompt, [image_array])
    
    # print("response_text:", response_text)

    if response_text == ERROR_CALLING_LLM:
        raise Exception("Error calling GPT-5 API")
    
    # 3. ç¡®ä¿å“åº”æ˜¯çº¯HTMLæ ¼å¼
    # ç®€å•æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«HTMLæ ‡ç­¾
    if not (response_text.strip().startswith('<') and response_text.strip().endswith('>')):
        print("mllmçš„è¾“å‡ºæ ¼å¼ä¸æ˜¯çº¯ç²¹çš„htmlæ ¼å¼ï¼ï¼ï¼")
        pass
    
    # 4. å°†mllmè¾“å‡ºçš„HTMLæ–‡æœ¬å…ˆä¿å­˜æˆhtmlæ–‡ä»¶ï¼Œå†æ¸²æŸ“ä¸ºå›¾åƒ
    html_path=html_save_path+f"test_{idx}.html"
    with open(html_path, "w", encoding="utf-8") as f:
        f.write(response_text)
    image_path=html_save_path+f"test_{idx}.png"
    flag = render_aligned_png(html_path, image_path)
    # æ¸²æŸ“æˆåŠŸ
    if flag:
    # 5.è¯»å–å›¾åƒå¹¶å­˜æˆnumpyæ ¼å¼
        returned_array = png_to_image_array(image_path)
        print("æˆåŠŸä¿å­˜å›¾åƒåˆ°ï¼š", image_path)
        return returned_array
    else:
        return None

######################### æµ‹è¯• #########################
if __name__ == '__main__':
    # å½“å‰guiç•Œé¢
    image_url="/home/zyh/zyh_documents/zla/ViMo/ViMo-Empowered_Agent/demo_exp/experiment_logs_20251215_161736/step_1/before_screenshot.png"
    image_array=png_to_image_array(image_url)
    action="Open the app: Settings"

    inferencer = MLLMInferencer(model_name="gpt-5")

    _post_figure_action(inferencer, image_array=image_array, action=action)



    # print(inferencer.openai_api_key)

    # user_prompt = USER_PROMPT_TEMPLATE.format(
    #     semantic_desc=action,
    # )
    # print(user_prompt)

    # # 2. è°ƒç”¨gpt5 APIè·å–HTMLå“åº”
    # response_text, _, _ = inferencer.predict_mm(user_prompt, [image_array])

    # print(response_text)

    # print("response_text:", response_text)

    # if response_text == ERROR_CALLING_LLM:
    #     raise Exception("Error calling GPT-5 API")

    # # 3. ç¡®ä¿å“åº”æ˜¯çº¯HTMLæ ¼å¼
    # # ç®€å•æ£€æŸ¥å“åº”æ˜¯å¦åŒ…å«HTMLæ ‡ç­¾
    # if not (response_text.strip().startswith('<') and response_text.strip().endswith('>')):
    #     # å¦‚æœä¸æ˜¯çº¯HTMLï¼Œå¯èƒ½éœ€è¦æå–HTMLéƒ¨åˆ†
    #     # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
    #     pass

    # html_path="test.html"
    # # 4. å°†HTMLå“åº”æ¸²æŸ“ä¸ºå›¾åƒ
    # with open(html_path, "w", encoding="utf-8") as f:
    #     f.write(response_text)

    # render_aligned_png(html_path, "test.png")